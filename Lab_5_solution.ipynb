{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73JHBwym-IfY"
      },
      "source": [
        "## Week 5 : Generative AI for Language Models (Recurrent neural networks, LSTM)\n",
        "```\n",
        "- Generative Artificial Intelligence (Fall semester 2023)\n",
        "- Professor: Muhammad Fahim\n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "## Contents\n",
        "```\n",
        "Lab Plan\n",
        "1. Dataset (SenseEval)\n",
        "2. Data Preprocessing\n",
        "3. Recurrent neural networks (PyTorch RNN)\n",
        "4. Long short-term memory (PyTorch LSTM)\n",
        "5. Self practice task\n",
        "```\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ix2fmCL_N6-"
      },
      "source": [
        "## Recap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VThX0jkS9_0D",
        "outputId": "41a090f9-15c1-43e8-f476-0e4e79116a36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preliminaries for processing the text\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "import torchtext\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGSqqYCE9poX"
      },
      "source": [
        "## Basics (Sequences and RNN)\n",
        "\n",
        "\n",
        "Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN's state. The core reason that recurrent nets are more exciting is that they allow us to operate over sequences of vectors\n",
        "\n",
        "![](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "### Mode details on the RNN cell\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment7.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ7f72pc9soF",
        "outputId": "79c3951c-31a9-4b39-832d-52355706b260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "simple_sequence = torch.Tensor([[0.3,1.9,4.5],[0.4,0.1,0.23],[0.7,0.91,0.43], [0.34,0.01,0.002]])\n",
        "\n",
        "simple_sequence = simple_sequence.unsqueeze(0)\n",
        "\n",
        "simple_sequence.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6sGNZV_Ahev"
      },
      "source": [
        "The `simple_sequence` variable represents a sequence of length 4, where each element (time-stamp) is represented by a feature vector of length 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG0rJymoAum9"
      },
      "source": [
        "## Basic RNN layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg1s20W5AtO9"
      },
      "outputs": [],
      "source": [
        "simple_rnn_layer = nn.RNN(input_size=3, hidden_size=1, num_layers = 1, bias = True, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLGIlMmzAgwU",
        "outputId": "d242feab-daa1-4d42-c0c3-e5433c836919"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0', tensor([[ 0.7076, -0.5184,  0.8364]])),\n",
              "             ('weight_hh_l0', tensor([[0.5579]])),\n",
              "             ('bias_ih_l0', tensor([0.4299])),\n",
              "             ('bias_hh_l0', tensor([0.6654]))])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ],
      "source": [
        "simple_rnn_layer.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHIgqbFnCbXz"
      },
      "outputs": [],
      "source": [
        "output_all, output_last = simple_rnn_layer(simple_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywk8pq3DC3l3",
        "outputId": "7ff81ea1-54f2-4f81-fffe-5172e111076e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9537]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "output_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8x_dSpDw3J",
        "outputId": "f38979d3-5571-4bac-975e-54a23421ea21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9994],\n",
              "         [0.9691],\n",
              "         [0.9654],\n",
              "         [0.9537]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "output_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXw0izpPIdP2"
      },
      "source": [
        "### Inside the RNN cell\n",
        "\n",
        "$$a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$$\n",
        "$$h^{(t)} = tanh(a^{(t)})$$\n",
        "\n",
        "where the parameters are the bias vectors `b` and `c` along with the weight matrices\n",
        "`U, V and W`, respectively for input-to-hidden, hidden-to-output and hidden-tohidden connections. <br>\n",
        "Lets see whats inside Pytorch and compare with our theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMEkOXUeuSCx"
      },
      "source": [
        "### Inside the RNN cell (1)\n",
        "\n",
        "$$h_t = tanh(W_{hi}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})$$\n",
        "\n",
        "where $h_t$ represents the hidden state at time $t$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7hrvKzdvBIG",
        "outputId": "21ff4e6b-e6ac-42c7-d3e2-8e04c1973df2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9994], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "wih = simple_rnn_layer.weight_ih_l0.squeeze(0)\n",
        "whh = simple_rnn_layer.weight_hh_l0.squeeze(0)\n",
        "\n",
        "bih = simple_rnn_layer.bias_ih_l0\n",
        "bhh = simple_rnn_layer.bias_hh_l0\n",
        "\n",
        "x = simple_sequence[0][0] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h1 = torch.tanh(torch.Tensor(torch.dot(x,wih) + bih  + torch.dot(whh,torch.Tensor([0.0])) + bhh))\n",
        "h1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGrxHjry0BWl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l52dYDXuz5Rj",
        "outputId": "9f16e1a1-5b6a-4b80-b8e5-5d150719e9e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9691], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "x = simple_sequence[0][1]\n",
        "\n",
        "h2 = torch.tanh(torch.Tensor(torch.dot(x, wih) + bih  + torch.dot(whh,h1) + bhh))\n",
        "h2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J_tOEYlMS1_"
      },
      "source": [
        "**Task** : Compute all the other hidden states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59rflO2pMefK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d75b37-bb04-49fe-e308-bd36f7c5d2a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0.9994], grad_fn=<TanhBackward0>),\n",
              " tensor([0.9691], grad_fn=<TanhBackward0>),\n",
              " tensor([0.9654], grad_fn=<TanhBackward0>),\n",
              " tensor([0.9537], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "result = []\n",
        "\n",
        "h_previous = torch.Tensor([0.0])\n",
        "\n",
        "for i in range(simple_sequence.shape[1]):\n",
        "  x = simple_sequence[0][i]\n",
        "  h_previous = torch.tanh(torch.Tensor(torch.dot(x, wih) + bih  + torch.dot(whh,h_previous) + bhh))\n",
        "  result.append(h_previous)\n",
        "\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mTHqb7vC6Pb"
      },
      "outputs": [],
      "source": [
        "# !pip install -U torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbmX_Gu_dJx"
      },
      "source": [
        "## 1. Dataset and Problem statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9gx5dyI_dl5"
      },
      "outputs": [],
      "source": [
        "## Downloading Dataset\n",
        "\n",
        "#!pip install wget\n",
        "import wget\n",
        "\n",
        "#Download and unzip dataset\n",
        "#wget.download(\"http://alt.qcri.org/semeval2016/task6/data/uploads/stancedataset.zip\")\n",
        "\n",
        "#!unzip stancedataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR_TlPCFAXHU"
      },
      "source": [
        "### 1.2 Read dataset to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfcB6BEuAa7d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"./StanceDataset/train.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Tweet\",\"Target\"])\n",
        "test_data = pd.read_csv(\"./StanceDataset/test.csv\", header=0, engine='python' ,encoding = \"latin-1\", usecols=[\"Tweet\",\"Target\"])\n",
        "\n",
        "test_data.query(\"Target != 'Donald Trump'\", inplace=True)\n",
        "\n",
        "labels_keys = {value: i for i, (value, count) in enumerate(train_data.Target.value_counts().items())}\n",
        "\n",
        "train_data['Target'] = train_data['Target'].apply(lambda x: labels_keys.get(x))\n",
        "test_data['Target'] = test_data['Target'].apply(lambda x: labels_keys.get(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp1lWAIyKnwu",
        "outputId": "4bd7693f-a2b8-4355-bd9b-f38a49d8232d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([dict_values([0, 1, 2, 3, 4])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "np.unique(labels_keys.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jICP8dVoFumF",
        "outputId": "416f5b2b-eb89-4e42-9876-287a5168789a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Tweet  Target\n",
              "0     @tedcruz And, #HandOverTheServer she wiped cle...       0\n",
              "1     Hillary is our best choice if we truly want to...       0\n",
              "2     @TheView I think our country is ready for a fe...       0\n",
              "3     I just gave an unhealthy amount of my hard-ear...       0\n",
              "4     @PortiaABoulger Thank you for adding me to you...       0\n",
              "...                                                 ...     ...\n",
              "2909  There's a law protecting unborn eagles, but no...       2\n",
              "2910  I am 1 in 3... I have had an abortion #Abortio...       2\n",
              "2911  How dare you say my sexual preference is a cho...       2\n",
              "2912  Equal rights for those 'born that way', no rig...       2\n",
              "2913  #POTUS seals his legacy w/ 1/2 doz wins. The #...       2\n",
              "\n",
              "[2914 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61c99b89-4c4f-4568-9060-59a29705bfdc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2909</th>\n",
              "      <td>There's a law protecting unborn eagles, but no...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2910</th>\n",
              "      <td>I am 1 in 3... I have had an abortion #Abortio...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2911</th>\n",
              "      <td>How dare you say my sexual preference is a cho...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>Equal rights for those 'born that way', no rig...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>#POTUS seals his legacy w/ 1/2 doz wins. The #...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2914 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61c99b89-4c4f-4568-9060-59a29705bfdc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61c99b89-4c4f-4568-9060-59a29705bfdc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61c99b89-4c4f-4568-9060-59a29705bfdc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dcaf6b43-2070-44c8-9cb6-8d8315080711\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcaf6b43-2070-44c8-9cb6-8d8315080711')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dcaf6b43-2070-44c8-9cb6-8d8315080711 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irqY1J9L_YSR"
      },
      "source": [
        "## 2.Data Preprocessing\n",
        "\n",
        "[`torchtext`](https://pytorch.org/text/stable/index.html) is a package that consists of data processing utilities and popular datasets for natural language\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKiydYFJAmuv"
      },
      "source": [
        "### 1.3 Clean, tokenize and create Vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vsiebp_AyT2"
      },
      "outputs": [],
      "source": [
        "def clean_ascii(text):\n",
        "  #remove non-ASCII chars from data\n",
        "  return ''.join(i for i in text if ord(i) < 128)\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(clean_ascii)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "counter = Counter()\n",
        "\n",
        "for _, row in train_data.iterrows():\n",
        "  counter.update(tokenizer(row[\"Tweet\"]))\n",
        "\n",
        "\n",
        "vocablary = vocab(counter, specials=(\"<pad>\",\"<unk>\"), min_freq=1)\n",
        "vocablary.set_default_index(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH3FpGZ_ug2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cd48d8-1c5a-43ac-9208-c21aca7e3873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@tedcruz',\n",
              " 'and',\n",
              " ',',\n",
              " '#handovertheserver',\n",
              " 'she',\n",
              " 'wiped',\n",
              " 'clean',\n",
              " '+',\n",
              " '30k',\n",
              " 'deleted',\n",
              " 'emails',\n",
              " 'explains',\n",
              " 'dereliction',\n",
              " 'of',\n",
              " 'duty/lies',\n",
              " 're',\n",
              " '#benghazi',\n",
              " 'etc',\n",
              " '#tcot',\n",
              " 'hillary',\n",
              " 'is',\n",
              " 'our',\n",
              " 'best',\n",
              " 'choice',\n",
              " 'if',\n",
              " 'we',\n",
              " 'truly',\n",
              " 'want',\n",
              " 'to',\n",
              " 'continue',\n",
              " 'being',\n",
              " 'a',\n",
              " 'progressive',\n",
              " 'nation',\n",
              " '.',\n",
              " '#ohio',\n",
              " '@theview',\n",
              " 'i',\n",
              " 'think',\n",
              " 'country',\n",
              " 'ready',\n",
              " 'for',\n",
              " 'female',\n",
              " 'pres',\n",
              " 'it',\n",
              " 'can',\n",
              " \"'\",\n",
              " 't',\n",
              " 'ever',\n",
              " 'be',\n",
              " 'just',\n",
              " 'gave',\n",
              " 'an',\n",
              " 'unhealthy',\n",
              " 'amount',\n",
              " 'my',\n",
              " 'hard-earned',\n",
              " 'money',\n",
              " 'away',\n",
              " 'the',\n",
              " 'big',\n",
              " 'gov',\n",
              " '&',\n",
              " 'untrustworthy',\n",
              " 'irs',\n",
              " '#whyimnotvotingforhillary',\n",
              " '@portiaaboulger',\n",
              " 'thank',\n",
              " 'you',\n",
              " 'adding',\n",
              " 'me',\n",
              " 'your',\n",
              " 'list',\n",
              " 'not',\n",
              " 'win',\n",
              " 'here',\n",
              " 's',\n",
              " 'hoping',\n",
              " 'dems',\n",
              " 'offer',\n",
              " 'real',\n",
              " 'candidate',\n",
              " 'like',\n",
              " 'warren',\n",
              " '#warren2016',\n",
              " 'respect',\n",
              " 'law',\n",
              " 'by',\n",
              " 'yes',\n",
              " 'needed',\n",
              " 'desperately',\n",
              " '#baltimoreriots',\n",
              " 'don',\n",
              " 'appointed',\n",
              " 'ambassador',\n",
              " 'post',\n",
              " '#stophillary2016',\n",
              " '@hillaryclinton',\n",
              " 'there',\n",
              " 'was',\n",
              " 'woman',\n",
              " 'with',\n",
              " 'integrity',\n",
              " 'honesty',\n",
              " 'would',\n",
              " 'vote',\n",
              " 'such',\n",
              " 'as',\n",
              " 'president',\n",
              " 'no',\n",
              " 'end',\n",
              " 'lawless',\n",
              " '#clintonfoundation',\n",
              " 'jail',\n",
              " 'butcher',\n",
              " '#arrest',\n",
              " 'rapist',\n",
              " '#billclinton',\n",
              " '#hillaryclinton',\n",
              " 'use',\n",
              " 'brain',\n",
              " 'keep',\n",
              " 'out',\n",
              " 'white',\n",
              " 'house',\n",
              " 'clinton2016',\n",
              " 'pandering',\n",
              " 'her',\n",
              " 'logo',\n",
              " '#clintonfoundationscandal',\n",
              " '#clintoncash',\n",
              " '@readyforhrc',\n",
              " 'us',\n",
              " 'presidency',\n",
              " 'testament',\n",
              " 'success',\n",
              " '#women',\n",
              " 'their',\n",
              " 'role',\n",
              " 'in',\n",
              " 'world',\n",
              " '@ciaraantaya',\n",
              " 'cuz',\n",
              " 'know',\n",
              " 'm',\n",
              " 'feminist',\n",
              " '2',\n",
              " 'million',\n",
              " 'bogus',\n",
              " 'followers',\n",
              " 'on',\n",
              " 'twitter',\n",
              " '@lindasuhler',\n",
              " 'name',\n",
              " 'rebecca',\n",
              " 'grandmother',\n",
              " 'immigrated',\n",
              " 'sunnybrook',\n",
              " 'farm',\n",
              " '@twitchyteam',\n",
              " 'where',\n",
              " 'campaign',\n",
              " 'store',\n",
              " 'question',\n",
              " '?',\n",
              " 'am',\n",
              " 'buy',\n",
              " 'some',\n",
              " 'gear',\n",
              " 'miracle',\n",
              " 'suddenly',\n",
              " '#democrats',\n",
              " 'mind',\n",
              " 'having',\n",
              " 'someone',\n",
              " 'who',\n",
              " 'voted',\n",
              " 'war',\n",
              " '@smileitsalicia',\n",
              " '@greekgummybear2',\n",
              " 'now',\n",
              " 'live',\n",
              " 'peace',\n",
              " 'doesn',\n",
              " 'put',\n",
              " 'anyone',\n",
              " 'prison',\n",
              " 'anymore',\n",
              " 'obviously',\n",
              " 'worried',\n",
              " 'about',\n",
              " 'own',\n",
              " 'future',\n",
              " 'only',\n",
              " 'way',\n",
              " 'support',\n",
              " 'elizabeth',\n",
              " 'ran',\n",
              " 'or',\n",
              " 'karl',\n",
              " 'marx',\n",
              " 'running',\n",
              " '#2016',\n",
              " '#clinton2016',\n",
              " '@homeofunclesam',\n",
              " '@scotsfyre',\n",
              " '@rwnutjob1',\n",
              " '@sa_hartdegen',\n",
              " 'too',\n",
              " 'old',\n",
              " 'understand',\n",
              " 'internet',\n",
              " 'that',\n",
              " 'fact',\n",
              " 'checked',\n",
              " 'because',\n",
              " 'communist',\n",
              " 'breadlines',\n",
              " 'are',\n",
              " 'thing',\n",
              " '!',\n",
              " '#nohillary',\n",
              " 'bad',\n",
              " 'wife',\n",
              " 'model',\n",
              " 'women',\n",
              " 'lawyer',\n",
              " 'first',\n",
              " 'lady',\n",
              " 'senator',\n",
              " 'horrible',\n",
              " 'secretary',\n",
              " 'state',\n",
              " 'everything',\n",
              " 'touches',\n",
              " 'ends',\n",
              " 'up',\n",
              " 'scam',\n",
              " 'lie',\n",
              " 'cover-up',\n",
              " 'failure',\n",
              " 'william',\n",
              " 'l',\n",
              " 'hrc',\n",
              " 'subject',\n",
              " 'dbl',\n",
              " 'standard',\n",
              " 'smh',\n",
              " 'come',\n",
              " '@billclinton',\n",
              " 'u',\n",
              " 'knew',\n",
              " '@clintonfdn',\n",
              " 'donations',\n",
              " 'b',\n",
              " 'scrutinized',\n",
              " 'spun',\n",
              " '#hillary',\n",
              " 'stop',\n",
              " '#pizza',\n",
              " 'today',\n",
              " 'garner',\n",
              " '#italian',\n",
              " '#msm',\n",
              " 'worthless',\n",
              " '#libertynothillary',\n",
              " '#hillno',\n",
              " 'america',\n",
              " 'great',\n",
              " 'again',\n",
              " 'march',\n",
              " '8',\n",
              " '2016',\n",
              " 'ohio',\n",
              " 'holding',\n",
              " 'primaries',\n",
              " 'date',\n",
              " 'change',\n",
              " '#ourchampion',\n",
              " '@rightzone',\n",
              " '@wethepeoplepets',\n",
              " 'let',\n",
              " 'hope',\n",
              " 'voters',\n",
              " 'remember',\n",
              " 'clinton',\n",
              " 'has',\n",
              " 'driven',\n",
              " 'car',\n",
              " 'since',\n",
              " '1996',\n",
              " '#clintonfakerealityshow',\n",
              " '@naughtybeyotch',\n",
              " '@therealmadman23',\n",
              " 'care',\n",
              " '#fiorina',\n",
              " 'but',\n",
              " 'seems',\n",
              " 'taking',\n",
              " '#sexist',\n",
              " 'gut',\n",
              " 'punches',\n",
              " '#media',\n",
              " '@foxnews',\n",
              " '@marthamaccallum',\n",
              " '@billhemmer',\n",
              " 'whose',\n",
              " 'opportunist',\n",
              " '#nohillary2016',\n",
              " '@womenintheworld',\n",
              " 'need',\n",
              " 're-establish',\n",
              " '#global',\n",
              " 'system',\n",
              " 'dominated',\n",
              " 'love',\n",
              " 'affection',\n",
              " 'have',\n",
              " '#moral_humane',\n",
              " 'rt',\n",
              " 'transparent',\n",
              " 'brick',\n",
              " 'wall',\n",
              " '@wsj',\n",
              " 'foundation',\n",
              " 'accepting',\n",
              " 'bribes',\n",
              " 'from',\n",
              " 'foreign',\n",
              " 'governments',\n",
              " '@josephbenning',\n",
              " 'agree',\n",
              " 'these',\n",
              " 'better',\n",
              " 'than',\n",
              " 'what',\n",
              " 'had',\n",
              " 'before',\n",
              " 'severe',\n",
              " 'cold',\n",
              " 'pneumonia',\n",
              " 'good',\n",
              " 'luck',\n",
              " 'afraid',\n",
              " 'answer',\n",
              " 'questions',\n",
              " 'press',\n",
              " 'why',\n",
              " 'do',\n",
              " 'potus',\n",
              " 'sorry',\n",
              " 'new',\n",
              " 'normal',\n",
              " 'folk',\n",
              " 'image',\n",
              " 'take',\n",
              " 'behgnazi',\n",
              " '0',\n",
              " 'policy',\n",
              " 'successes',\n",
              " 'ceo',\n",
              " 'pay',\n",
              " 'target',\n",
              " 'election',\n",
              " 'makes',\n",
              " 'more',\n",
              " 'most',\n",
              " 'drank',\n",
              " 'kool-aid',\n",
              " '@nbcnews',\n",
              " 'including',\n",
              " 'repealing',\n",
              " 'amendment',\n",
              " 'go',\n",
              " 'promoting',\n",
              " 'liar',\n",
              " 'impeached',\n",
              " 'husband',\n",
              " '#wakeupamerica',\n",
              " 'lets',\n",
              " 'back',\n",
              " 'whos',\n",
              " 'democrats',\n",
              " '@anthonycumia',\n",
              " 'elected',\n",
              " 'transition',\n",
              " 'team',\n",
              " 'together',\n",
              " 'smoothly',\n",
              " 'move',\n",
              " 'racist',\n",
              " 'sexist',\n",
              " '#thatchampion',\n",
              " 'got',\n",
              " 'kicked',\n",
              " 'off',\n",
              " '#watergate',\n",
              " 'due',\n",
              " 'misconduct',\n",
              " 'droid',\n",
              " 'programmed',\n",
              " 'say',\n",
              " 'things',\n",
              " '-',\n",
              " 'thinks',\n",
              " 'work',\n",
              " 'so',\n",
              " 'isn',\n",
              " '@jvollmer08',\n",
              " '@hillaryforia',\n",
              " '#freedom_justice_equality_education',\n",
              " 'innovation',\n",
              " 'development',\n",
              " 'make',\n",
              " '#happy_life',\n",
              " 'utopia',\n",
              " 'probably',\n",
              " 'perfect',\n",
              " 'everyone--which',\n",
              " 'this',\n",
              " 'beginning',\n",
              " 'conversation',\n",
              " 'edge',\n",
              " 'seat',\n",
              " 'start',\n",
              " 'volunteering',\n",
              " 'presidential',\n",
              " 'excited',\n",
              " '#cantwait',\n",
              " '@futuretxleader',\n",
              " 'everyone',\n",
              " '#elpaso',\n",
              " '#texas',\n",
              " '#marcorubio',\n",
              " '#utep',\n",
              " '#newamericancentury',\n",
              " '#future',\n",
              " '#rub',\n",
              " 'laid',\n",
              " 'down',\n",
              " 'abortion',\n",
              " 'bioethics',\n",
              " 'class',\n",
              " '#catholic',\n",
              " '@tooprettyclub',\n",
              " 'ok',\n",
              " '#gop',\n",
              " 'males',\n",
              " 'telling',\n",
              " 'body',\n",
              " 'kid',\n",
              " 'adoption',\n",
              " '#sorrynotsorry',\n",
              " '@redalert',\n",
              " '-there',\n",
              " 'should',\n",
              " 'stigma',\n",
              " 'butchering',\n",
              " 'pre-born',\n",
              " 'children',\n",
              " 'its',\n",
              " 'horrendous',\n",
              " 'crime',\n",
              " 'against',\n",
              " 'humanity',\n",
              " '#murder',\n",
              " 'problem',\n",
              " 'then',\n",
              " 'enough',\n",
              " 'faith',\n",
              " '#gaystapo',\n",
              " '#socialism',\n",
              " 'life',\n",
              " 'basic',\n",
              " 'human',\n",
              " 'right',\n",
              " 'rise',\n",
              " 'shine',\n",
              " 'day',\n",
              " 'alive',\n",
              " 'god',\n",
              " '4',\n",
              " 'another',\n",
              " 'precious',\n",
              " '#christian',\n",
              " '#teamjesus',\n",
              " 'lmao',\n",
              " 'school',\n",
              " 'giving',\n",
              " 'feminism',\n",
              " 'they',\n",
              " '#wtf',\n",
              " '@asasoltan',\n",
              " 'putting',\n",
              " 'choices',\n",
              " 'won',\n",
              " 'heart',\n",
              " 'over',\n",
              " 'yaaaaaas',\n",
              " '#shahs',\n",
              " 'last',\n",
              " 'meeting',\n",
              " 'year',\n",
              " 'tonight',\n",
              " '7',\n",
              " '00',\n",
              " 'pm',\n",
              " 'case',\n",
              " 'hall',\n",
              " 'room',\n",
              " '334a',\n",
              " 'one',\n",
              " 'all',\n",
              " 'pizza',\n",
              " 'pop',\n",
              " 'will',\n",
              " 'provided',\n",
              " '17%',\n",
              " 'population',\n",
              " 'equivalent',\n",
              " 'residents',\n",
              " 'york',\n",
              " 'florida',\n",
              " 'pennsylvania',\n",
              " 'outrage',\n",
              " 'listening',\n",
              " 'look',\n",
              " 'at',\n",
              " 'radar',\n",
              " '#prayfornepal',\n",
              " 'believe',\n",
              " 'power',\n",
              " 'pray',\n",
              " '#nepal',\n",
              " '#baltimore',\n",
              " '#isis',\n",
              " '#kenya',\n",
              " '#genderchange',\n",
              " '#injustice',\n",
              " '#slavery',\n",
              " '#racism',\n",
              " '#middleeast',\n",
              " 'planned',\n",
              " 'parenthood',\n",
              " 'lines',\n",
              " 'pockets',\n",
              " 'while',\n",
              " 'sacrificing',\n",
              " 'altar',\n",
              " 'try',\n",
              " 'resolve',\n",
              " 'problems',\n",
              " 'eliminating',\n",
              " '#popefrancis',\n",
              " '@thekeyisprayer',\n",
              " 'give',\n",
              " 'wrong',\n",
              " '-abraham',\n",
              " 'lincoln',\n",
              " 'people',\n",
              " 'religious',\n",
              " 'rights',\n",
              " 'consent',\n",
              " 'reproductive',\n",
              " 'remind',\n",
              " 'ourselves',\n",
              " 'means',\n",
              " 'willing',\n",
              " 'until',\n",
              " 'hurts',\n",
              " 'mother',\n",
              " 'teresa',\n",
              " 'beautiful',\n",
              " 'teacher',\n",
              " 'basically',\n",
              " 'said',\n",
              " 'embroyo',\n",
              " 'nothing',\n",
              " 'skin',\n",
              " 'blood',\n",
              " 'fine',\n",
              " '#smartlady',\n",
              " '@showtruth',\n",
              " 'keeping',\n",
              " 'pregnant',\n",
              " 'safe',\n",
              " 'reason',\n",
              " 'though',\n",
              " '@rosaryrevival',\n",
              " 'when',\n",
              " '#praytherosary',\n",
              " 'lest',\n",
              " 'forget',\n",
              " '#prayforpersecutedchurch',\n",
              " '#prayforisrael',\n",
              " '#prayforukraine',\n",
              " '#cogar',\n",
              " '@refcom_ie',\n",
              " 'get',\n",
              " '#questions',\n",
              " '#d',\n",
              " '#ballott',\n",
              " '#ireland',\n",
              " '#dail',\n",
              " 'stuck',\n",
              " 'll',\n",
              " '#help',\n",
              " '#drugswar',\n",
              " '#landwar',\n",
              " '#etc',\n",
              " '#tanks',\n",
              " 'yep',\n",
              " 'defunding',\n",
              " 'pp',\n",
              " 'mean',\n",
              " 'fewer',\n",
              " 'abortions',\n",
              " 'dead',\n",
              " '#prochoice',\n",
              " '#1in3',\n",
              " '@mrprolife',\n",
              " 'force',\n",
              " 'risk',\n",
              " 'health',\n",
              " 'sanity',\n",
              " 'doomed',\n",
              " 'pregnancy',\n",
              " 'whether',\n",
              " 'wants',\n",
              " 'completely',\n",
              " 'person',\n",
              " 'carrying',\n",
              " 'gay',\n",
              " 'marriage',\n",
              " 'pro-life',\n",
              " 'adopt',\n",
              " 'babies',\n",
              " 'been',\n",
              " 'aborted',\n",
              " 'manila',\n",
              " 'tv',\n",
              " 'monday',\n",
              " '#pacquiao',\n",
              " 'appeals',\n",
              " '@indonesiapresident',\n",
              " '-don',\n",
              " 'execute',\n",
              " '#maryjaneveloso',\n",
              " '#deathrow',\n",
              " '#drugtrafficking',\n",
              " 'far',\n",
              " 'he',\n",
              " 'watched',\n",
              " '#aftertiller',\n",
              " 'whole',\n",
              " 'perspective',\n",
              " 'choose',\n",
              " '#womensrights',\n",
              " '@explicit0ceans',\n",
              " 'either',\n",
              " 'kids',\n",
              " 'esp',\n",
              " 'prepared',\n",
              " 'sense',\n",
              " 'true',\n",
              " 'progressives',\n",
              " 'toward',\n",
              " 'greater',\n",
              " 'inclusion',\n",
              " 'protections',\n",
              " 'marginalized',\n",
              " 'standing',\n",
              " 'unborn',\n",
              " 'mt',\n",
              " '@prolifepolitics-',\n",
              " 'senate',\n",
              " 'sc',\n",
              " 'pain-capable',\n",
              " 'child',\n",
              " 'protection',\n",
              " 'act',\n",
              " 'could',\n",
              " 'early',\n",
              " 'wed',\n",
              " 'contact',\n",
              " 'senators',\n",
              " 'equal',\n",
              " 'freedom',\n",
              " 'fear',\n",
              " 'rape',\n",
              " 'sexual',\n",
              " 'objectification',\n",
              " 'abort',\n",
              " 'whoa',\n",
              " 'sex',\n",
              " 'involved',\n",
              " 'grateful',\n",
              " 'control',\n",
              " 'without',\n",
              " 'govt',\n",
              " 'influence',\n",
              " '#antichoice',\n",
              " 'leaders',\n",
              " '#abvote',\n",
              " 'sadly',\n",
              " 'insurance',\n",
              " 'plans',\n",
              " 'cover',\n",
              " 'price',\n",
              " 'quite',\n",
              " 'high',\n",
              " '@britt_ghiroli',\n",
              " '@mboyle1',\n",
              " 'mayor',\n",
              " 'baltimore',\n",
              " 'rioters',\n",
              " '#blacklivesmatter',\n",
              " '#except2democrats',\n",
              " '#sanger',\n",
              " 'much',\n",
              " 'fun',\n",
              " 'younger',\n",
              " 'friends',\n",
              " 'expecting',\n",
              " '#beentheredonethat',\n",
              " '#chooselife',\n",
              " 'illegal',\n",
              " 'kill',\n",
              " 'unhatched',\n",
              " 'eagle',\n",
              " 'egg',\n",
              " 'legal',\n",
              " 'baby',\n",
              " 'isright',\n",
              " 'refuse',\n",
              " 'shame',\n",
              " 'insult',\n",
              " 'accessing',\n",
              " 'healthcare',\n",
              " 'pro-birth',\n",
              " 'after',\n",
              " 'itself',\n",
              " '#makesnosense',\n",
              " '#prowomen',\n",
              " 'funny',\n",
              " 'male',\n",
              " 'politicians',\n",
              " 'deciding',\n",
              " 'born',\n",
              " 'months',\n",
              " 'premature',\n",
              " 'perfectly',\n",
              " 'somehow',\n",
              " 'killing',\n",
              " 'cause',\n",
              " 'claim',\n",
              " 'made',\n",
              " 'mistake',\n",
              " 'nobody',\n",
              " 'spouse',\n",
              " '@corey_frizzell',\n",
              " '@peiliberalparty',\n",
              " 'islanders',\n",
              " 'different',\n",
              " 'definitions',\n",
              " 'timely',\n",
              " 'access',\n",
              " '#irony',\n",
              " '#peipoli',\n",
              " '#peivotes',\n",
              " '@docjp',\n",
              " 'pressure',\n",
              " 'job',\n",
              " 'failing',\n",
              " 'miserably',\n",
              " 'promises',\n",
              " '#pjnet',\n",
              " '#amnesty',\n",
              " '#obamacare',\n",
              " 'how',\n",
              " '#liberals',\n",
              " 'accuse',\n",
              " '#conservatives',\n",
              " 'fund',\n",
              " 'help',\n",
              " 'friend',\n",
              " 'figure',\n",
              " 'going',\n",
              " 'stay',\n",
              " 'spend',\n",
              " 'night',\n",
              " '@jimddaniels1',\n",
              " 'plenty',\n",
              " 'reasons',\n",
              " 'christians',\n",
              " 'least',\n",
              " 'which',\n",
              " 'stand',\n",
              " '(',\n",
              " 'w/dems',\n",
              " ')',\n",
              " 'dear',\n",
              " 'lord',\n",
              " 'ur',\n",
              " 'blessings',\n",
              " 'forgive',\n",
              " 'sins',\n",
              " 'strength',\n",
              " 'energy',\n",
              " 'busy',\n",
              " 'ahead',\n",
              " '#blessed',\n",
              " '#hope',\n",
              " '#semst',\n",
              " 'blessed',\n",
              " 'peacemakers',\n",
              " 'shall',\n",
              " 'called',\n",
              " 'matthew',\n",
              " '5',\n",
              " '9',\n",
              " '#scripture',\n",
              " '#peace',\n",
              " 'conformed',\n",
              " 'transformed',\n",
              " 'renewing',\n",
              " '#ispeaklife',\n",
              " '#god',\n",
              " '#2014',\n",
              " 'salah',\n",
              " 'prayed',\n",
              " '#focus',\n",
              " '#understanding',\n",
              " '#allah',\n",
              " 'warns',\n",
              " '#lazy',\n",
              " 'prayers',\n",
              " 'done',\n",
              " '#show',\n",
              " 'surah',\n",
              " 'al-maoon',\n",
              " '107',\n",
              " '4-6',\n",
              " 'houses',\n",
              " 'display',\n",
              " 'yourselves',\n",
              " 'times',\n",
              " 'ignorance',\n",
              " '[quran',\n",
              " '33',\n",
              " '33]',\n",
              " '#islam',\n",
              " 'unsure',\n",
              " 'something',\n",
              " 'halal',\n",
              " 'haram',\n",
              " 'leave',\n",
              " '#safeguard',\n",
              " '#deen',\n",
              " '#rule',\n",
              " 'papa',\n",
              " 'shower',\n",
              " 'patience',\n",
              " '#worththewait',\n",
              " 'scoc',\n",
              " 'ruled',\n",
              " 'canadians',\n",
              " 'religion',\n",
              " 'tell',\n",
              " 'harper',\n",
              " 'dummy',\n",
              " 'his',\n",
              " 'bless',\n",
              " 'canada',\n",
              " '#cdnpoli',\n",
              " 'wow',\n",
              " 'unsubstantiated',\n",
              " 'claims',\n",
              " 'spooks',\n",
              " 'whe',\n",
              " 'were',\n",
              " 'gullible',\n",
              " '@jvx242',\n",
              " 'kind',\n",
              " 'modesty',\n",
              " 'arrogant',\n",
              " 'christopher',\n",
              " 'hitchens',\n",
              " '2/2',\n",
              " '#funny',\n",
              " 'able',\n",
              " 'whatever',\n",
              " '#freedom',\n",
              " 'those',\n",
              " 'treat',\n",
              " 'prophet',\n",
              " 'mohammad',\n",
              " 'pbuh',\n",
              " '@prayerbullets',\n",
              " 'righteousness',\n",
              " 'joy',\n",
              " 'kingdom',\n",
              " 'established',\n",
              " '-rom',\n",
              " '14',\n",
              " '17',\n",
              " 'hold',\n",
              " 'allow',\n",
              " 'powerful',\n",
              " 'time',\n",
              " 'fight',\n",
              " 'battle',\n",
              " '#believe',\n",
              " '#truth',\n",
              " '#butgod',\n",
              " 'sees',\n",
              " 'invisible',\n",
              " 'believes',\n",
              " 'incredible',\n",
              " 'receives',\n",
              " 'impossible',\n",
              " 'muhammad',\n",
              " 'exchange',\n",
              " 'gift',\n",
              " 'increase',\n",
              " 'towards',\n",
              " '#world',\n",
              " '#quran',\n",
              " '@ax2n38',\n",
              " '@halcyondon',\n",
              " '@tag65',\n",
              " '#separationofchurchandstate',\n",
              " '#ting',\n",
              " '#gwg',\n",
              " '#gfyh',\n",
              " 'celebrity',\n",
              " 'atheism',\n",
              " 'irk',\n",
              " '#initforthemoney',\n",
              " 'leaving',\n",
              " 'christianity',\n",
              " 'enables',\n",
              " 'once',\n",
              " 'rejected',\n",
              " '#freethinker',\n",
              " '#christianity',\n",
              " 'clear',\n",
              " 'thoughts',\n",
              " 'sky',\n",
              " 'looking',\n",
              " 'heavens',\n",
              " 'earth',\n",
              " 'connected',\n",
              " 'entity',\n",
              " 'separated',\n",
              " 'them',\n",
              " 'havemade',\n",
              " 'water',\n",
              " 'every',\n",
              " 'living',\n",
              " 'quran',\n",
              " '21',\n",
              " '30',\n",
              " 'please',\n",
              " 'grown',\n",
              " 'ups',\n",
              " 'may',\n",
              " 'throw',\n",
              " 'towel',\n",
              " 'second',\n",
              " 'half',\n",
              " 'devil',\n",
              " 'enemy',\n",
              " 'battleground',\n",
              " 'plays',\n",
              " '-josh',\n",
              " 'ricketson',\n",
              " '#rush',\n",
              " '#rushswag',\n",
              " 'odds',\n",
              " 'already',\n",
              " 'stacked',\n",
              " 'favor',\n",
              " 'call',\n",
              " 'him',\n",
              " 'savior',\n",
              " 'comes',\n",
              " 'scientific',\n",
              " 'discoveries',\n",
              " '#religious',\n",
              " 'bullshit',\n",
              " 'texts',\n",
              " 'others',\n",
              " 'envy',\n",
              " 'focus',\n",
              " 'calling',\n",
              " 'become',\n",
              " 'dream',\n",
              " 'kingdom-sized',\n",
              " 'dreams',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "list(counter.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBN8wJgbuH5A"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, OrderedDict\n",
        "unk_token = '<unk>'\n",
        "default_index = -1\n",
        "v2 = vocab(OrderedDict([(token, 1) for token in list(counter.keys())]), specials=[unk_token])\n",
        "v2.set_default_index(default_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E64fNpzDA9eB"
      },
      "source": [
        "### 1.4 Padding Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcNrk5nPBEt5"
      },
      "outputs": [],
      "source": [
        "# Do padding\n",
        "def data_process(raw_text_iter,max_len=64):\n",
        "  batch = []\n",
        "  for item in raw_text_iter:\n",
        "    res = [v2[token] for token in tokenizer(item)]\n",
        "    if len(res) > max_len :\n",
        "      res = res[:max_len]\n",
        "    if len(res) < max_len :\n",
        "      res += ([v2[\"<pad>\"]] * (max_len-len(res)))\n",
        "    batch.append(res)\n",
        "  pad_data = torch.tensor(batch, dtype=torch.long)\n",
        "  return pad_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdUgotn0BbcC"
      },
      "source": [
        "## Create Dataloaders\n",
        "\n",
        "\n",
        "<font color='red'>**Task**</font>: Create validation dataloader from train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh6y1XX0_b7K"
      },
      "outputs": [],
      "source": [
        "max_len = 64\n",
        "embedding_size = 10\n",
        "n_classes = len(np.unique(train_data.Target.values))\n",
        "\n",
        "#Create Dataloader\n",
        "train_tensor = data_process(train_data.Tweet.values)\n",
        "tgts_tensor = torch.from_numpy(train_data.Target.values)\n",
        "\n",
        "# Test\n",
        "test_tensor = data_process(test_data.Tweet.values)\n",
        "test_labels = torch.from_numpy(test_data.Target.values)\n",
        "\n",
        "# Valid\n",
        "# TODO : Create validation\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(train_tensor, tgts_tensor)\n",
        "test_dataset = TensorDataset(test_tensor, test_labels)\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_iterator = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "valid_iterator = DataLoader(test_dataset, batch_size=32, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpjyrjUXNVBS"
      },
      "source": [
        "## Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04oPle1jNSzU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "    super().__init__()\n",
        "    # TODO: Define the RNN layer and fully connected layer\n",
        "\n",
        "    self.embedding_layer = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn_cell = nn.RNN(embedding_dim, hidden_dim, num_layers)\n",
        "    self.fc_layer = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "    \"\"\"\n",
        "    Foward pass method\n",
        "    \"\"\"\n",
        "    # TODO: Define the forward method\n",
        "    embedings = self.embedding_layer(text)\n",
        "    x = self.rnn_cell(embedings)\n",
        "    x = self.fc_layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwvso1QU4vt1"
      },
      "source": [
        "### Training Model\n",
        "\n",
        "<font color='red'>**Task**</font>: Define a function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js1liVNffvTn"
      },
      "outputs": [],
      "source": [
        "def accuracy_calculator(preds, y):\n",
        "  \"\"\"Returns accuracy per batch\"\"\"\n",
        "  # TODO implement a function that returns accuracy per batch\n",
        "  return sum(np.array(preds) == np.array(y)) / len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnXH-OUcojrM"
      },
      "source": [
        "\n",
        "\n",
        "<font color='red'>**Task**</font>: Define a training loop for training the RNN model<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roKuxTXW4vL7"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in dataloader:\n",
        "    # TODO: Define a training loop for training the RNN model\n",
        "    text, label = batch\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model.forward(text)\n",
        "    loss = criterion(predictions, label)\n",
        "\n",
        "    acc = accuracy_calculator(predictions, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "  return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zDj1sBHogEh"
      },
      "source": [
        "<font color='red'>**Task**</font>: Define a function for evaluating the model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvWCA7YC4uEe"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_batches, criterion, device):\n",
        "  eval_loss = 0\n",
        "  eval_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_batches:\n",
        "      # TODO : Define a function for evaluating the model on test set\n",
        "      batch = torch.tensor(batch).to(device)\n",
        "      text, label = batch\n",
        "      predictions = model.forward(text)\n",
        "      loss = criterion(predictions, label)\n",
        "\n",
        "      acc = accuracy_calculator(predictions, label)\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc.item()\n",
        "\n",
        "  return eval_loss / len(data_batches), eval_acc / len(data_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOQ5WxteE5fo"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfHRImuoE8GV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5000875f-56e5-4787-c6dc-da231d44eb42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-8097e94afb73>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#make model instance and send it to training device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = len(vocablary) #input dimension is the dimension of the one-hot vectors\n",
        "embedding_dim = 100\n",
        "hidden_dim = 10 #size of the hidden states\n",
        "output_dim = 1\n",
        "num_layers = 1\n",
        "\n",
        "# TODO: create the RNN model\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim, num_layers)\n",
        "\n",
        "# define loss function and optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#make model instance and send it to training device\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYTuVZotGVIu"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaBj11amrXXh"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O6x3Df06i6t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "ad94f57b-dda5-4be5-b6c0-a095d071d532"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-184-7f75f9cbbc5d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-183-72e9cb366d22>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# TODO: Define a training loop for training the RNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "  valid_loss, valid_acc = evaluate_model(model, valid_iterator, criterion, device)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'best-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1} , Train [Loss:  {train_loss:.3f}  Acc :{train_acc*100:.2f}], Val.[Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9_fs8d7Djk"
      },
      "source": [
        "### Load best model for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXfK85vt7HzD"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best-model.pt')) #Load the best model\n",
        "test_loss, test_acc = evaluate_model(model, test_iterator, criterion)\n",
        "print(f'Accuracy on test data : {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o8n7Ht9BivV"
      },
      "source": [
        "## How to check for vanishing/exploding gradients ?\n",
        "\n",
        "* This is a problem that involves weights in earlier layers of the network. Why? (hint : stochastic gradient descent)\n",
        "* The vanishing gradient problem is a problem that causes major difficulty when training a neural network.\n",
        "* If the gradient is vanishingly small, then the weights update during backpropergation are going to be vanishingly small as well.\n",
        "\n",
        "\n",
        "**How to detect this?**\n",
        "1. Monitor the weights i.e use TensorBoard and log the weights\n",
        "2. Make checkpoints and manualy log to track :\n",
        "```\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.grad.norm())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3i9vVk0NTMP"
      },
      "source": [
        "# Long short-term memory (LSTM)\n",
        "\n",
        "![](https://www.researchgate.net/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DICQLXyDa4yu"
      },
      "source": [
        "## Basics of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOBCKWGBa4VW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3d-Zsqoa-uz"
      },
      "source": [
        "<font color='red'>**Task**</font>: Using\n",
        "The SemEval-2016 Stance Dataset. train a LSTM model for sentiment analysis. In the dataset there is a column **`sentiment`**, use it as target. To make the task binary classification remove samples in the dataset with label **`other`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clb1EJpjb0K-"
      },
      "outputs": [],
      "source": [
        "# TODO: Data preprocessing and creation of dataloaders (train, validation & test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKtmFY2Gtb0k"
      },
      "source": [
        "## Define Simple LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKrYR85uMbwO"
      },
      "outputs": [],
      "source": [
        "class SimpleLstm(nn.Module):\n",
        "  def __init__(self, embedding_dim ,vocab_size , hidden_dim=10, output_dim=1, n_layers=1):\n",
        "    super().__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm_layer = nn.LSTM(...)\n",
        "\n",
        "    self.output_layer = nn.Linear(...)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "    embedded = self.embedding(x)\n",
        "    outputs, (hidden, cell) = self.lstm_layer(embedded)\n",
        "\n",
        "    # TODO :\n",
        "    pred = self.output_layer(...)\n",
        "    return pred\n",
        "\n",
        "vocab_size = len(vocablary)\n",
        "embedding_size = 64\n",
        "output_dim = None # TODO\n",
        "model = SimpleLstm(embedding_dim=embedding_size, vocab_size=vocab_size, hidden_dim=10,output_dim=output_dim).to(device).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9YUoTK_tgps"
      },
      "source": [
        "## Training and Evaluating LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cktrfvhYcFY7"
      },
      "outputs": [],
      "source": [
        "# TODO : You will need to redefine accuracy_calculator function\n",
        "def accuracy_calculator(pred, y):\n",
        "  return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaxNfSeRMrpV"
      },
      "outputs": [],
      "source": [
        "# Train loop\n",
        "criterion = None\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "criterion = criterion.to(device)\n",
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate_model(model, valid_iterator, criterion)\n",
        "\n",
        "  print(f'Epoch: {epoch+1} , Train [Loss:  {train_loss:.3f}  Acc :{train_acc*100:.2f}], Val.[Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EukNgkJzsV_L"
      },
      "source": [
        "## <center>Self practice Task</center>\n",
        "\n",
        "```\n",
        "1. From Senseval data RNN and LSTM model to do prediction of the tags on ambiguous words\n",
        "2. Use pretrained embeddings instead of training from scratch with pretrained embeddings (glove or fasttext)\n",
        "```\n",
        "**To download Senseval data example**\n",
        "```\n",
        "from nltk.corpus import senseval as se\n",
        "nltk.download('senseval')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2O-Tb8ktRDC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}